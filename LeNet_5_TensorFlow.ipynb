{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet-5-TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjeJvsMXPjbV"
      },
      "source": [
        "# Import packages.\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9EhfkJ8Qt0S"
      },
      "source": [
        "# Load data.\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ8KIiNeVjB9"
      },
      "source": [
        "# Scale data to a range of 0 and 1.\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TsuN0BQ0Dlo"
      },
      "source": [
        "# Expand a dimension at end because model expects [batch_size, 32, 32, 1] shape.\n",
        "x_train, x_test = tf.expand_dims(x_train, -1), tf.expand_dims(x_test, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KnZa-Lfv9LD"
      },
      "source": [
        "# Scale data from 28x28 to 32x32.\n",
        "x_train = tf.image.resize(x_train, size=(32,32))\n",
        "x_test = tf.image.resize(x_test, size=(32,32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abNY1z_yul4e"
      },
      "source": [
        "# Convert y_train and y_test to one hot encoded vector.\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vqeeuaPQwOF"
      },
      "source": [
        "# Define model.\n",
        "def LeNet5():\n",
        "    input = keras.layers.Input(shape=(32, 32, 1))\n",
        "    \n",
        "    c1 = keras.layers.Conv2D(filters=6, kernel_size=5, strides=1, padding='valid', activation='relu')(input)\n",
        "    p1 = keras.layers.MaxPool2D(pool_size=(2, 2), strides=2)(c1)\n",
        "\n",
        "    c2 = keras.layers.Conv2D(filters=16, kernel_size=5, strides=1, padding='valid', activation='relu')(p1)\n",
        "    p2 = keras.layers.MaxPool2D(pool_size=(2, 2), strides=2)(c2)\n",
        "\n",
        "    fl = keras.layers.Flatten()(p2)\n",
        "\n",
        "    d1 = keras.layers.Dense(units=120)(fl)\n",
        "    d2 = keras.layers.Dense(units=84)(d1)\n",
        "    d3 = keras.layers.Dense(units=10)(d2)\n",
        "\n",
        "    output = keras.layers.Softmax()(d3)\n",
        "\n",
        "    return keras.models.Model(inputs=input, outputs=output, name='LeNet-5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcVX1XGVQ3mB"
      },
      "source": [
        "# Hyperparameters.\n",
        "learning_rate = 1e-3\n",
        "batch_size = 32\n",
        "epochs = 25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9EdTC9-fY2b"
      },
      "source": [
        "# Loss function and optimizer.\n",
        "loss_fn = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSgT-wRJQ0em"
      },
      "source": [
        "# Instantiate and compile model.\n",
        "model = LeNet5()\n",
        "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk6_ez49Q_z-"
      },
      "source": [
        "# Train.\n",
        "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0lDmtBp14kf"
      },
      "source": [
        "# Plot accuracy.\n",
        "# Copied from: https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EBFkHUr2nV0"
      },
      "source": [
        "# Plot loss.\n",
        "# Copied from: https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}